name: Generate Documentation

on:
  workflow_run:
    workflows: ["Update Configs"]
    types:
      - completed
  workflow_dispatch:

permissions:
  contents: write

jobs:
  generate-docs:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch' }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6
        with:
          ref: ${{ github.ref }}
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: pip install pyyaml

      - name: Generate Category READMEs
        run: |
          python3 << 'SCRIPT'
          import os
          import urllib.parse
          import yaml
          
          yaml.add_multi_constructor("!", lambda loader, suffix, node: None, Loader=yaml.SafeLoader)

          REPO_URL = "https://github.com/${{ github.repository }}/blob/main"
          CATEGORIES = {
              "THEYAMLS/Official_Examples": "Mihomo å®˜æ–¹ç¤ºä¾‹ (Official)",
              "THEYAMLS/General_Config": "é€šç”¨è¿›é˜¶é…ç½® (General Config)",
              "THEYAMLS/Smart_Mode": "Smart æ¨¡å¼ / è·¯ç”±ä¸“ç”¨ (Smart Mode)",
              "THEYAMLS/Mobile_Modules": "Android æ‰‹æœºæ¨¡å— (Mobile Modules)"
          }
          IGNORE_FILES = ["README.md", "LICENSE", "release_body.md"]

          def safe_get(data, keys, default="N/A"):
              val = data
              try:
                  for key in keys:
                      val = val[key]
                  return val
              except:
                  return default

          def get_file_size(path):
              try:
                  size = os.path.getsize(path)
                  if size < 1024: return f"{size} B"
                  return f"{size/1024:.1f} KB"
              except: return "Unknown"

          def read_file_content(file_path):
              content = ""
              try:
                  with open(file_path, "r", encoding="utf-8") as f:
                      content = f.read()
              except UnicodeDecodeError:
                  try:
                      with open(file_path, "r", encoding="gb18030", errors="ignore") as f:
                          content = f.read()
                  except Exception:
                      return None
              if "\t" in content:
                  content = content.replace("\t", "  ")
              return content

          def analyze_single_config(file_path):
              try:
                  raw_content = read_file_content(file_path)
                  if not raw_content: return None
                  data = yaml.safe_load(raw_content)
                  if not isinstance(data, dict): return None

                  info = {}
                  info["mode"] = safe_get(data, ["mode"], "Rule")
                  info["ipv6"] = "âœ…" if str(safe_get(data, ["ipv6"])).lower() == "true" else "ğŸš«"
                  info["allow_lan"] = "âœ…" if str(safe_get(data, ["allow-lan"])).lower() == "true" else "ğŸš«"
                  info["tun"] = "âœ… å¼€å¯" if safe_get(data, ["tun", "enable"], False) else "ğŸš« å…³é—­"
                  info["port_mixed"] = safe_get(data, ["mixed-port"], "-")
                  info["port_ctrl"] = safe_get(data, ["external-controller"], "-")
                  
                  ports_list = []
                  p_mix = data.get("mixed-port")
                  if p_mix: ports_list.append(f"| Mixed (æ··åˆ) | {p_mix} | HTTP/SOCKS |")
                  p_http = data.get("port")
                  if p_http: ports_list.append(f"| HTTP | {p_http} | ä»… HTTP |")
                  p_socks = data.get("socks-port")
                  if p_socks: ports_list.append(f"| SOCKS5 | {p_socks} | ä»… SOCKS |")
                  p_tproxy = data.get("tproxy-port")
                  if p_tproxy: ports_list.append(f"| TProxy | {p_tproxy} | é€æ˜ä»£ç† (UDP) |")
                  p_redir = data.get("redir-port")
                  if p_redir: ports_list.append(f"| Redirect | {p_redir} | é€æ˜ä»£ç† (TCP) |")
                  p_ctrl = data.get("external-controller")
                  if p_ctrl: ports_list.append(f"| Controller | {p_ctrl} | æ§åˆ¶é¢æ¿ |")

                  listeners = data.get("listeners", [])
                  if listeners and isinstance(listeners, list):
                      for l in listeners:
                          if isinstance(l, dict):
                              name = l.get("name", "Unknown")
                              port = l.get("port", "?")
                              l_type = l.get("type", "mixed")
                              ports_list.append(f"| ğŸ‘‚ {name} | {port} | {l_type} |")
                  
                  info["ports_display_lines"] = ports_list
                  groups = data.get("proxy-groups", [])
                  info["group_count"] = len(groups) if isinstance(groups, list) else 0
                  rules = data.get("rules", [])
                  info["rule_count"] = len(rules) if isinstance(rules, list) else 0
                  
                  info["groups_raw"] = []
                  if isinstance(groups, list):
                      for pg in groups:
                          if isinstance(pg, dict):
                              name = pg.get("name", "Unknown")
                              type_ = pg.get("type", "select")
                              icon = "ğŸš€"
                              if "auto" in type_ or "url-test" in type_: icon = "â™»ï¸"
                              elif "fallback" in type_: icon = "ğŸ”§"
                              elif "load-balance" in type_: icon = "âš–ï¸"
                              elif "select" in type_: icon = "ğŸ‘†"
                              info["groups_raw"].append(f"| {icon} {name} | `{type_}` |")

                  info["dns_raw"] = []
                  dns = data.get("dns", {})
                  if isinstance(dns, dict) and dns.get("enable", False):
                      nameservers = dns.get("nameserver", [])
                      if isinstance(nameservers, list):
                          for ns in nameservers:
                              if isinstance(ns, str):
                                  provider = "DoT" if "tls://" in ns else "DoH" if "https://" in ns else "UDP"
                                  info["dns_raw"].append(f"| {provider} | `{ns}` |")
                  
                  return info
              except Exception as e:
                  return None

          def generate_category_readme(folder_path, title):
              rel_folder = os.path.relpath(folder_path, ".")
              all_files = []
              for root, dirs, files in os.walk(folder_path):
                  dirs[:] = [d for d in dirs if not d.startswith('.')]
                  for f in files:
                      if f.endswith(('.yaml', '.yml')) and f not in IGNORE_FILES:
                          full_path = os.path.join(root, f)
                          rel_path = os.path.relpath(full_path, folder_path)
                          all_files.append((rel_path, full_path))
              
              if not all_files:
                  return None

              configs_data = {}
              for rel_path, full_path in all_files:
                  parsed = analyze_single_config(full_path)
                  if parsed:
                      configs_data[rel_path] = {
                          "file_size": get_file_size(full_path),
                          "parsed": parsed,
                          "full_path": full_path
                      }

              if not configs_data:
                  return None

              lines = []
              lines.append(f"# ğŸ“‚ {title}")
              lines.append("")
              lines.append(f"[ğŸ”™ è¿”å›ä¸»é¡µ](../README.md)")
              lines.append("")
              lines.append("> ğŸ¤– **è‡ªåŠ¨æŠ€æœ¯åˆ†ææŠ¥å‘Š** | Auto-generated Technical Report")
              lines.append("")

              if len(configs_data) > 1:
                  lines.append("## âš”ï¸ é…ç½®æ¨ªå‘å¯¹æ¯” (Comparison)")
                  lines.append("")
                  
                  display_items = list(configs_data.items())[:10]
                  headers = ["ç‰¹æ€§ / æ–‡ä»¶"] + [f"`{os.path.basename(p)}`" for p, _ in display_items]
                  lines.append("| " + " | ".join(headers) + " |")
                  lines.append("| :--- " + "| :--- " * len(display_items) + "|")
                  
                  size_row = ["**å¤§å°**"] + [d.get("file_size", "N/A") for _, d in display_items]
                  lines.append("| " + " | ".join(size_row) + " |")
                  
                  rows = [
                      ("port_mixed", "æ··åˆç«¯å£"), ("port_ctrl", "é¢æ¿ç«¯å£"),
                      ("mode", "è¿è¡Œæ¨¡å¼"), ("tun", "TUN æ¨¡å¼"),
                      ("group_count", "ç­–ç•¥ç»„æ•°"), ("rule_count", "è§„åˆ™æ¡æ•°"),
                  ]
                  for key, label in rows:
                      row_content = [f"**{label}**"]
                      for _, data in display_items:
                          val = data.get("parsed", {}).get(key, "N/A")
                          if key in ["group_count", "rule_count"]: val = f"**{val}**"
                          row_content.append(str(val))
                      lines.append("| " + " | ".join(row_content) + " |")
                  lines.append("")

              lines.append("## ğŸ“„ é…ç½®æ–‡ä»¶è¯¦è§£ (Details by Author)")
              lines.append("")
              
              by_author = {}
              for rel_path, data in configs_data.items():
                  author = rel_path.split(os.sep)[0] if os.sep in rel_path else "Unknown"
                  if author not in by_author:
                      by_author[author] = []
                  by_author[author].append((rel_path, data))
              
              for author, items in sorted(by_author.items()):
                  lines.append(f"### ğŸ‘¤ {author}")
                  lines.append("")
                  
                  for rel_path, data in items:
                      filename = os.path.basename(rel_path)
                      info = data["parsed"]
                      file_url = f"{REPO_URL}/{rel_folder}/{urllib.parse.quote(rel_path.replace(os.sep, '/'))}"
                      
                      lines.append(f"#### ğŸ“ {filename}")
                      lines.append(f"- **è·¯å¾„**: `{rel_path}` | **å¤§å°**: {data['file_size']} | **[Raw]({file_url})**")
                      
                      port_lines = info.get("ports_display_lines", [])
                      if port_lines:
                          lines.append("- **ç«¯å£é…ç½®**:")
                          lines.append("| ç±»å‹ | ç«¯å£ | è¯´æ˜ |")
                          lines.append("| :--- | :--- | :--- |")
                          for line in port_lines:
                              lines.append(line)
                          lines.append("")
                      
                      groups_raw = info.get("groups_raw", [])
                      if groups_raw:
                          lines.append(f"<details>")
                          lines.append(f"<summary>ğŸ” ç­–ç•¥ç»„æ¶æ„ ({len(groups_raw)}ä¸ª)</summary>")
                          lines.append("")
                          lines.append("| ç­–ç•¥ç»„ | ç±»å‹ |")
                          lines.append("| :--- | :--- |")
                          lines.extend(groups_raw[:15])
                          if len(groups_raw) > 15:
                              lines.append(f"| ... | è¿˜æœ‰ {len(groups_raw)-15} ä¸ª |")
                          lines.append("</details>")
                          lines.append("")
                  lines.append("---")
                  lines.append("")

              return "\n".join(lines)

          for folder_name, title in CATEGORIES.items():
              if os.path.isdir(folder_name):
                  readme_content = generate_category_readme(folder_name, title)
                  if readme_content:
                      readme_path = os.path.join(folder_name, "README.md")
                      with open(readme_path, "w", encoding="utf-8") as f:
                          f.write(readme_content)
                      print(f"âœ… Generated: {readme_path}")
          SCRIPT

      - name: Generate Root README
        run: |
          python3 << 'SCRIPT'
          import os
          import re

          def parse_shell_script(script_path):
              if not os.path.exists(script_path):
                  return []
              
              with open(script_path, 'r', encoding='utf-8', errors='ignore') as f:
                  content = f.read()
              
              results = []
              pattern = r'(https?://[^|\s"\']+)\|([^"\n]+?\.ya?ml)'
              matches = re.findall(pattern, content)
              
              for url, output_path in matches:
                  output_path = output_path.strip()
                  
                  if 'raw.githubusercontent.com' in url:
                      parts = url.split('/')
                      author = parts[4] if len(parts) > 4 else 'unknown'
                  elif 'github.com' in url:
                      parts = url.split('/')
                      author = parts[3] if len(parts) > 3 else 'unknown'
                  elif 'gist.github.com' in url:
                      parts = url.split('/')
                      author = parts[3] if len(parts) > 3 else 'gist'
                  else:
                      author = url.split('/')[2].split('.')[0]
                  
                  category = 'Other'
                  if 'General_Config' in output_path:
                      category = 'General'
                  elif 'Smart_Mode' in output_path:
                      category = 'Smart'
                  elif 'Mobile_Modules' in output_path:
                      category = 'Mobile'
                  elif 'Official_Examples' in output_path:
                      category = 'Official'
                  
                  filename = os.path.basename(url)
                  parts = url.split('/')
                  if 'raw.githubusercontent.com' in url and len(parts) >= 5:
                      repo_url = f"https://github.com/{parts[3]}/{parts[4]}"
                  elif 'github.com' in url and len(parts) >= 5:
                      repo_url = f"https://github.com/{parts[3]}/{parts[4]}"
                  else:
                      repo_url = url
                  
                  results.append({
                      'author': author,
                      'filename': filename,
                      'output': output_path.replace('THEYAMLS/', ''),
                      'category': category,
                      'source_repo': repo_url,
                      'full_url': url
                  })
              return results

          scripts_map = {
              'General_Config': '.github/scripts/download-general.sh',
              'Smart_Mode': '.github/scripts/download-smart.sh', 
              'Mobile_Modules': '.github/scripts/download-mobile.sh',
              'Official_Examples': '.github/scripts/download-official.sh'
          }
          
          all_data = {}
          for cat, script in scripts_map.items():
              all_data[cat] = parse_shell_script(script)

          author_desc = {
              'HenryChiao': 'å…¨èƒ½å‹é…ç½®ï¼Œæ•´åˆå¤šç§ç­–ç•¥ï¼›Proç³»åˆ—ç­–ç•¥ç»„æ›´åŠ ç»†åŒ–',
              '666OS': 'è§„åˆ™ç­–ç•¥å¤šè€Œå…¨ï¼Œæ ¼å¼ç¾è§‚ï¼›OneTouch ä¸ºä¸€é”®è¿ç²¾ç®€ç‰ˆ',
              'JohnsonRan': 'ç»å…¸å¤§ä¼—é…ç½®ï¼Œå«å›½å®¶åˆ†ç»„ï¼›åŒ…å«å»å¹¿å‘Šç­‰å®ç”¨åŠŸèƒ½',
              'Lanlan13-14': 'æ¶µç›–å…¨é‡ç‰ˆã€ç²¾ç®€ç‰ˆ(Lite)åŠå»å¹¿å‘Šç‰ˆ(NoAd)',
              'liandu2024': 'ä¾§é‡é«˜å¯ç”¨æ€§ (Fallback)ï¼Œè‡ªåŠ¨åˆ‡æ¢æ•…éšœèŠ‚ç‚¹',
              'Yiteei': 'æ³¨é‡Šæå…¶å®Œæ•´ï¼Œç»“æ„æ¸…æ™°ï¼Œé€‚åˆè¿›é˜¶å­¦ä¹ ä¸é­”æ”¹',
              'ClashConnectRules': 'ç¤¾åŒºè‡ªç”¨é…ç½®ï¼ŒæŒç»­æ›´æ–°',
              'yyhhyyyyyy': 'è‡ªç”¨ä»£ç†é…ç½®ï¼Œç»“æ„ç®€å•',
              'echs-top': 'ç¤¾åŒºçƒ­é—¨ Smart é…ç½®',
              'qichiyuhub': 'ä¾§é‡ AI ä¸æ™ºèƒ½åˆ†æµç­–ç•¥',
              'iKeLee': 'ç»å…¸ Clash æ¨¡æ¿é£æ ¼',
              'sunfing': 'ç»å…¸ Clash æ¨¡æ¿é£æ ¼',
              'liuran001': 'ç»å…¸ Clash æ¨¡æ¿é£æ ¼',
              'wanswu': 'ç»å…¸ Clash æ¨¡æ¿é£æ ¼',
              'GitMetaio': 'æ–°æ‰‹å‹å¥½ã€å¼€ç®±å³ç”¨ï¼Œè§„åˆ™åˆ†ç»„å¤§ä¼—åŒ–ä¸”æ¸…æ™°',
              'boxproxy': 'ç»å…¸ Box çš„åˆ†æ”¯ç‰ˆæœ¬ï¼ŒåŠ å…¥ WiFi å¯åœé€»è¾‘',
              'akashaProxy': 'ç®€å•å®Œå¤‡çš„é…ç½®ç»“æ„ï¼ŒåŒ…å«è¯¦ç»†çš„å›½å®¶/åœ°åŒºåˆ†ç»„',
              'AXEVO': 'æç®€é£æ ¼é…ç½®ï¼Œæ¨¡å—åŒ–è®¾è®¡ï¼Œè½»é‡é«˜æ•ˆ',
              'Metacubex': 'Mihomo å®˜æ–¹ç¤ºä¾‹ï¼Œæœ€çº¯å‡€åŸºç¡€'
          }

          lines = []
          lines.append("# ğŸ“¦ mihomo_yamls")
          lines.append("")
          lines.append("> ğŸ”„ **è‡ªåŠ¨åŒæ­¥çš„ Mihomo (Clash.Meta) é…ç½®æ–‡ä»¶ä»“åº“**")
          lines.append("> ")
          lines.append("> æœ¬ä»“åº“é€šè¿‡ GitHub Actions æ¯æ—¥è‡ªåŠ¨åŒæ­¥å„ä¸Šæ¸¸ä½œè€…çš„é…ç½®æ–‡ä»¶ï¼Œå¹¶ç”ŸæˆæŠ€æœ¯åˆ†ææ–‡æ¡£ä¸ OpenClash è¦†å†™é…ç½®ã€‚")
          lines.append("")
          lines.append("## ğŸ“‚ å¿«é€Ÿå¯¼èˆª")
          lines.append("")
          lines.append("| åˆ†ç±» | è¯´æ˜ | é…ç½®æ•°é‡ | æ–‡æ¡£ |")
          lines.append("| :--- | :--- | :--- | :--- |")
          
          for cat_key in ['General_Config', 'Smart_Mode', 'Mobile_Modules', 'Official_Examples']:
              items = all_data.get(cat_key, [])
              count = len(items)
              if count > 0:
                  title_map = {
                      'General_Config': 'é€šç”¨è¿›é˜¶é…ç½®',
                      'Smart_Mode': 'Smart æ¨¡å¼ / è·¯ç”±ä¸“ç”¨',
                      'Mobile_Modules': 'Android æ¨¡å—ä¸“ç”¨',
                      'Official_Examples': 'Mihomo å®˜æ–¹ç¤ºä¾‹'
                  }
                  desc_map = {
                      'General_Config': 'é€‚åˆ PCã€Mac åŠæ™®é€šæ‰‹æœºç«¯',
                      'Smart_Mode': 'éœ€é…åˆ Smart é­”æ”¹å†…æ ¸ä½¿ç”¨',
                      'Mobile_Modules': 'é€‚åˆå·² Root çš„ Android è®¾å¤‡',
                      'Official_Examples': 'çº¯å‡€åŸºç¡€ï¼Œé€‚åˆå­¦ä¹ '
                  }
                  lines.append(f"| **{title_map[cat_key]}** | {desc_map[cat_key]} | {count} ä¸ª | [æŸ¥çœ‹](THEYAMLS/{cat_key}/README.md) |")
          
          lines.append("")
          lines.append("---")
          lines.append("")

          categories = [
              ('General_Config', 'é€šç”¨è¿›é˜¶é…ç½® (General Config)', 'é€‚åˆ PCã€Mac åŠæ™®é€šæ‰‹æœºç«¯ä½¿ç”¨çš„å…¨åŠŸèƒ½é…ç½®ã€‚'),
              ('Smart_Mode', 'Smart æ¨¡å¼ / è·¯ç”±ä¸“ç”¨ (Smart Mode)', 'ä¸“ä¸º Smart æ ¸å¿ƒã€OpenClash æˆ–è½¯è·¯ç”±ç¯å¢ƒä¼˜åŒ–ã€‚éœ€é…åˆ Smart é­”æ”¹å†…æ ¸ä½¿ç”¨ã€‚'),
              ('Mobile_Modules', 'Android æ¨¡å—ä¸“ç”¨ (Mobile Modules)', 'é€‚åˆå·²è·å– Root æƒé™ (Magisk/KernelSU/APatch) çš„ç”¨æˆ·ã€‚'),
              ('Official_Examples', 'Mihomo å®˜æ–¹ Wiki ç¤ºä¾‹ (Official)', 'æœ€çº¯å‡€ã€æœ€åŸºç¡€ï¼Œé€‚åˆä»é›¶å¼€å§‹æ„å»ºæˆ–å­¦ä¹ é…ç½®è¯­æ³•ã€‚')
          ]

          for cat_key, title, desc in categories:
              items = all_data.get(cat_key, [])
              if not items:
                  continue
              
              lines.append(f"### {title}")
              lines.append(f"> {desc}")
              lines.append("")
              lines.append("| ğŸ‘¤ ä½œè€… (Author) | ğŸ“¦ é…ç½®æ¸…å• (Configs) | ğŸ“ æè¿° (Description) | ğŸ”— æº¯æº (Source) |")
              lines.append("| :--- | :--- | :--- | :--- |")
              
              by_author = {}
              for item in items:
                  auth = item['author']
                  if auth not in by_author:
                      by_author[auth] = []
                  by_author[auth].append(item)
              
              for author, files in sorted(by_author.items()):
                  file_links = "<br>".join([
                      f"ğŸ“„ [`{f['filename']}`](THEYAMLS/{f['output']})" 
                      for f in files
                  ])
                  
                  description = author_desc.get(author, 'ç¤¾åŒºç²¾é€‰é…ç½®')
                  repo_name = files[0]['source_repo'].split('/')[-1] if '/' in files[0]['source_repo'] else author
                  source_link = f"[{author}/{repo_name}]({files[0]['source_repo']})"
                  
                  lines.append(f"| **{author}** | {file_links} | {description} | {source_link} |")
              
              lines.append("")
              lines.append("[ğŸ”™ è¿”å›é¡¶éƒ¨](#-mihomo_yamls)")
              lines.append("")

          with open("README.md", "w", encoding="utf-8") as f:
              f.write("\n".join(lines))
          print("âœ… Generated root README.md")
          SCRIPT

      - name: Generate OpenClash Configs
        run: |
          python3 << 'SCRIPT'
          import os
          import yaml
          from urllib.parse import quote

          SOURCE_BASE = "THEYAMLS"
          SOURCE_DIRS = [
              "THEYAMLS/Official_Examples",
              "THEYAMLS/General_Config", 
              "THEYAMLS/Smart_Mode",
              "THEYAMLS/Mobile_Modules"
          ]
          OUTPUT_BASE = "Overwrite/THEOPENCLASH"
          GITHUB_REPO = "${{ github.repository }}"
          REPO_RAW_BASE = f"https://raw.githubusercontent.com/{GITHUB_REPO}/main"
          IGNORE_FILES = ["README.md", "LICENSE", "release_body.md"]
          
          yaml.add_multi_constructor("!", lambda loader, suffix, node: None, Loader=yaml.SafeLoader)

          def parse_yaml_file(file_path):
              try:
                  with open(file_path, "r", encoding="utf-8") as f:
                      content = f.read()
                  if "\t" in content:
                      content = content.replace("\t", "  ")
                  data = yaml.safe_load(content)
                  if not isinstance(data, dict):
                      return {"providers": [], "has_providers": False}
                  
                  providers_dict = data.get("proxy-providers", {})
                  if not isinstance(providers_dict, dict) or not providers_dict:
                      return {"providers": [], "has_providers": False}
                  
                  return {"providers": list(providers_dict.keys()), "has_providers": True}
              except:
                  return {"providers": [], "has_providers": False}

          os.makedirs(OUTPUT_BASE, exist_ok=True)
          
          for source_dir in SOURCE_DIRS:
              if not os.path.exists(source_dir):
                  continue
              
              for root, dirs, files in os.walk(source_dir):
                  dirs[:] = [d for d in dirs if not d.startswith(".")]
                  for filename in files:
                      if not filename.endswith((".yaml", ".yml")) or filename in IGNORE_FILES:
                          continue
                      
                      file_path = os.path.join(root, filename)
                      parsed = parse_yaml_file(file_path)
                      
                      if not parsed["has_providers"]:
                          continue
                      
                      rel_path = os.path.relpath(root, SOURCE_BASE)
                      raw_url = f"{REPO_RAW_BASE}/{SOURCE_BASE}/{rel_path.replace(os.sep, '/')}/{quote(filename)}"
                      
                      output_dir = os.path.join(OUTPUT_BASE, rel_path)
                      os.makedirs(output_dir, exist_ok=True)
                      
                      conf_filename = os.path.splitext(filename)[0] + ".conf"
                      output_path = os.path.join(output_dir, conf_filename)
                      
                      lines = [
                          "# --- OpenClash Overwrite Config ---",
                          f"# Source: {filename}",
                          f"# Generated: Auto-generated by GitHub Actions",
                          "",
                          "[General]",
                          "DISABLE_UDP_QUIC = 1",
                          f"DOWNLOAD_FILE = url={raw_url}, path=/etc/openclash/config/{filename}, cron=0 6 * * *, force=false",
                          f"CONFIG_FILE = /etc/openclash/config/{filename}",
                          "SUB_INFO_URL = $EN_KEY1",
                          "",
                          "[Overwrite]",
                          "# EN_KEY: Environment variables for subscription URLs"
                      ]
                      
                      for idx, provider_name in enumerate(parsed["providers"], start=1):
                          lines.append(f'ruby_map_edit "$CONFIG_FILE" "[\'proxy-providers\']" "{provider_name}" "[\'url\']" "$EN_KEY{idx}"')
                      
                      with open(output_path, "w", encoding="utf-8") as f:
                          f.write("\n".join(lines))
                      print(f"âœ… OpenClash: {output_path}")
          SCRIPT

      - name: Generate OpenClash READMEs
        run: |
          python3 << 'SCRIPT'
          import os
          
          OUTPUT_BASE = "Overwrite/THEOPENCLASH"
          if not os.path.exists(OUTPUT_BASE):
              exit(0)
          
          for category in os.listdir(OUTPUT_BASE):
              cat_path = os.path.join(OUTPUT_BASE, category)
              if not os.path.isdir(cat_path):
                  continue
              
              conf_files = [f for f in os.listdir(cat_path) if f.endswith(".conf")]
              if not conf_files:
                  continue
              
              lines = [
                  f"# ğŸ“ {category}",
                  "",
                  "## ğŸ“‹ é…ç½®æ–‡ä»¶åˆ—è¡¨",
                  "",
                  "| æ–‡ä»¶ | è¯´æ˜ |",
                  "| :--- | :--- |"
              ]
              
              for cf in sorted(conf_files):
                  lines.append(f"| `{cf}` | OpenClash è¦†å†™é…ç½® |")
              
              lines.extend([
                  "",
                  "[ğŸ”™ è¿”å› OpenClash æ€»è§ˆ](../README.md)"
              ])
              
              with open(os.path.join(cat_path, "README.md"), "w", encoding="utf-8") as f:
                  f.write("\n".join(lines))

          lines = [
              "# ğŸ“¦ OpenClash è¦†å†™é…ç½®æ–‡ä»¶æ€»è§ˆ",
              "",
              "> ğŸ¤– **è‡ªåŠ¨ç”Ÿæˆ** | åŸºäº THEYAMLS é…ç½®æ–‡ä»¶è‡ªåŠ¨ç”Ÿæˆ",
              "",
              "## ğŸ“‚ åˆ†ç±»ç›®å½•",
              ""
          ]
          
          for category in sorted(os.listdir(OUTPUT_BASE)):
              if os.path.isdir(os.path.join(OUTPUT_BASE, category)):
                  lines.append(f"- ğŸ“ **[{category}](./{category}/README.md)**")
          
          lines.append("")
          lines.append("[ğŸ  è¿”å›é¡¹ç›®ä¸»é¡µ](../../README.md)")
          
          with open(os.path.join(OUTPUT_BASE, "README.md"), "w", encoding="utf-8") as f:
              f.write("\n".join(lines))
          SCRIPT

      - name: Generate INI README
        run: |
          python3 << 'SCRIPT'
          import os
          import re

          def parse_ini_script():
              script_path = ".github/scripts/download-ini.sh"
              if not os.path.exists(script_path):
                  return {}
              
              with open(script_path, 'r', encoding='utf-8') as f:
                  content = f.read()
              
              urls_match = re.search(r'urls=\((.*?)\)', content, re.DOTALL)
              if not urls_match:
                  return {}
              
              urls = re.findall(r'https?://[^\s"\']+', urls_match.group(1))
              categories = {"ACL4Category": [], "Airport": [], "Ordinary": []}
              
              for url in urls:
                  if 'ACL4SSR' in url:
                      cat = "ACL4Category"
                  elif 'jklolixxs' in url or '/customized/' in url or 'Mazeorz/airports' in url:
                      cat = "Airport"
                  else:
                      cat = "Ordinary"
                  
                  if 'raw.githubusercontent.com' in url:
                      author = url.split('/')[4]
                  elif 'github.com' in url:
                      author = url.split('/')[3]
                  elif 'gist' in url:
                      author = url.split('/')[3]
                  else:
                      author = url.split('/')[2].split('.')[0]
                  
                  categories[cat].append({
                      'author': author,
                      'filename': url.split('/')[-1],
                      'url': url
                  })
              return categories

          cat_data = parse_ini_script()
          base_path = "Overwrite/THEINI"
          if not os.path.exists(base_path):
              exit(0)

          lines = [
              "# ğŸ“‚ INI è¦†å†™é…ç½®é›†åˆ (THEINI)",
              "",
              "> ğŸ”„ è‡ªåŠ¨åŒæ­¥çš„ SubConverter/Clash è¿œç¨‹é…ç½® (INI)",
              "",
              "## åˆ†ç±»ç´¢å¼•",
              ""
          ]

          cat_names = {
              "ACL4Category": ("ğŸ›¡ï¸ ACL4SSR ç³»åˆ—", "åŸºäº ACL4SSR é¡¹ç›®çš„ç»å…¸è§„åˆ™é›†"),
              "Airport": ("âœˆï¸ æœºåœºå®šåˆ¶ç‰ˆ", "å„å¤§æœºåœºæä¾›çš„ä¸“å±å®šåˆ¶é…ç½®"),
              "Ordinary": ("ğŸ“‹ é€šç”¨é…ç½®", "ç¤¾åŒºç»´æŠ¤çš„å…¶ä»–é€šç”¨è§„åˆ™é…ç½®")
          }

          for cat_key, items in cat_data.items():
              if not items:
                  continue
              title, desc = cat_names.get(cat_key, (cat_key, ""))
              lines.append(f"- **{title}**: {desc} ({len(items)} ä¸ª)")
          
          lines.append("")
          
          for cat_key, items in cat_data.items():
              if not items:
                  continue
              title, desc = cat_names.get(cat_key, (cat_key, ""))
              lines.append(f"## {title}")
              lines.append(f"> {desc}")
              lines.append("")
              lines.append("| ğŸ‘¤ ä½œè€…/æ¥æº | ğŸ“„ é…ç½®æ–‡ä»¶ | ğŸ”— åŸå§‹é“¾æ¥ |")
              lines.append("| :--- | :--- | :--- |")
              
              for item in items:
                  lines.append(f"| **{item['author']}** | `{item['filename']}` | [Source]({item['url']}) |")
              lines.append("")

          lines.append("## ğŸ“Š ç›®å½•ç»“æ„")
          lines.append("```text")
          try:
              import subprocess
              tree_out = subprocess.run(["tree", base_path, "-L", "3", "--dirsfirst", "--charset", "utf-8"],
                  capture_output=True, text=True)
              lines.append(tree_out.stdout.strip())
          except:
              pass
          lines.append("```")

          with open(os.path.join(base_path, "README.md"), "w", encoding="utf-8") as f:
              f.write("\n".join(lines))
          SCRIPT

      - name: Commit and Push
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "41898282+github-actions[bot]@users.noreply.github.com"
          
          git add .
          if git diff --staged --quiet; then
            echo "âœ… No changes detected."
            exit 0
          fi
          
          git commit -m "ğŸ¤– Auto: Generate all docs & configs $(date +'%Y-%m-%d')"
          git pull origin ${{ github.ref_name }} --rebase --autostash || true
          git push origin HEAD:${{ github.ref_name }}
